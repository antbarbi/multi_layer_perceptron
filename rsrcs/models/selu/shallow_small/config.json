{
    "layers": [
      {"units": 16, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 16, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 16, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 16, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 2, "activation": "softmax", "initializer": "xavierUniform"}      
    ],
    "learning_rate": 0.00004,
    "batch_size": 8,
    "epochs": 2000,
    "loss_function": "binaryCrossentropy",
    "use_momentum": true,
    "momentum": 0.8
  }
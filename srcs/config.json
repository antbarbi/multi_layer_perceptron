{
    "layers": [
      {"units": 24, "activation": "selu"},
      {"units": 24, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 24, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 24, "activation": "selu", "initializer": "lecunNormal"},
      {"units": 2, "activation": "softmax", "initializer": "xavierUniform"}
    ],
    "learning_rate": 0.0001,
    "batch_size": 8,
    "epochs": 300,
    "loss_function": "binaryCrossentropy"
  }